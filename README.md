# OlivFeeling
ëª¨ë¸í•™ìŠµ ë° ì¶”ì²œ 
## ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)  
2. [ABSA ë¼ë²¨ë§ ì „ëµ](#ABSA-ë¼ë²¨ë§-ì „ëµ)    
3. [ëª¨ë¸ í•™ìŠµ (LSTM & Bi-LSTM+Attention)](#ëª¨ë¸-í•™ìŠµ-LSTM--Bi-LSTMAttention)  
4. [ì‹¤ì‹œê°„ ì¶”ì²œ ëŒ€ì‹œë³´ë“œ (Streamlit)](#ì‹¤ì‹œê°„-ì¶”ì²œ-ëŒ€ì‹œë³´ë“œ-Streamlit)
   

## í”„ë¡œì íŠ¸ ê°œìš”
- **ëª©í‘œ**: ë¦¬ë·°ì—ì„œ `ë¯¸ë°±`, `ë³´ìŠµ`, `íŠ¸ëŸ¬ë¸” ì™„í™”`, `í”¼ë¶€ ë³´í˜¸`, `ë…¸í™” ë°©ì§€` ë“± **5ê°œ ê¸°ëŠ¥**ì— ëŒ€í•œ ê°ì„±(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)ì„ ìë™ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ì¶”ì²œ ì—”ì§„ì„ êµ¬í˜„  
- **íŒŒì´í”„ë¼ì¸**:  
  1. ì†ì„± ê¸°ë°˜ ìë™ ë¼ë²¨ë§  
  2. ë©€í‹° ë ˆì´ë¸” ë²¡í„°í™”  
  3. LSTM ê³„ì—´ ëª¨ë¸ í•™ìŠµ (Bi-LSTM + Attention í¬í•¨)  
  4. Streamlit ëŒ€ì‹œë³´ë“œë¡œ ê°œì¸í™” ì¶”ì²œ  

## ABSA ë¼ë²¨ë§ ì „ëµ
1. **ì†ì„± ì‚¬ì „ ì •ì˜**  
   - ë¶„ì„ ëŒ€ìƒ ê¸°ëŠ¥: `ë¯¸ë°±`, `ë³´ìŠµ`, `íŠ¸ëŸ¬ë¸”`, `ë³´í˜¸`, `ë…¸í™”ë°©ì§€`  
   - ê° ì†ì„±ê³¼ ì—°ê´€ëœ í‚¤ì›Œë“œ ë§¤í•‘  
   ```python
   aspect_keywords = {
     'ë¯¸ë°±': ['ë¯¸ë°±','í†¤ì—…','í™”ì´íŠ¸ë‹','í•˜ì–˜ì§'],
     'ë³´ìŠµ': ['ë³´ìŠµ','ì´‰ì´‰','ìˆ˜ë¶„','ì†ë‹¹ê¹€','ê±´ì¡°í•˜ì§€'],
     'íŠ¸ëŸ¬ë¸”': ['íŠ¸ëŸ¬ë¸”','ì—¬ë“œë¦„','ìê·¹','ì§„ì •','ë¶‰ì–´ì§'],
     'ë³´í˜¸': ['ìì™¸ì„ ','ì°¨ë‹¨','ë³´í˜¸ë§‰','ë°©ì–´'],
     'ë…¸í™”ë°©ì§€': ['ì£¼ë¦„','íƒ„ë ¥','ë…¸í™”','ì•ˆí‹°ì—ì´ì§•']
   }

2. ê°ì„± í‚¤ì›Œë“œ ì •ì˜
```python
positive_words = ['ì¢‹ë‹¤', 'ì¢‹ì•„ìš”', 'ì´‰ì´‰í•˜ë‹¤', 'ë§Œì¡±', 'ê°œì„ ', 'ì§„ì •ëë‹¤', 'ê´œì°®ë‹¤', 'í¡ìˆ˜', 'íš¨ê³¼', 'ì¶”ì²œ''ğŸ‘','â¤ï¸','ğŸ˜','ê°•ì¶”','í•©ê²©','ë§›ì§‘','ì¬êµ¬ë§¤']
negative_words = ['ë³„ë¡œ', 'ìê·¹ì ', 'íŠ¸ëŸ¬ë¸”ë‚¬ë‹¤', 'ê±´ì¡°í•˜ë‹¤', 'ë”°ê°‘ë‹¤', 'íš¨ê³¼ì—†ë‹¤', 'ë¶ˆí¸í•˜ë‹¤', 'ë’¤ì§‘ì–´ì§', 'ì‹¤ë§', 'ì•„ì‰¬ì›Œ','í”¼ë¡œê°ì„ ëŠë¼ë‹¤','ê³¼í•˜ë‹¤','ì—¬ë“œë¦„']
```

### ì„ê³„ì¹˜(Threshold)

ëª¨ë¸ì´ `0.0`~`1.0` ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ì¶œë ¥í•  ë•Œ, ì´ë¥¼ **ê¸ì •/ë¶€ì •/ì¤‘ë¦½** ê°™ì€ í™•ì‹¤í•œ íƒœê·¸ë¡œ ë°”ê¿€ ê¸°ì¤€ê°’ì„ **ì„ê³„ì¹˜**ë¼ê³  í•¨

#### 1. ê¸°ë³¸ ê°œë…
- ëª¨ë¸ ì¶œë ¥(ì˜ˆ: `prob = 0.7`)ì´ **ì„ê³„ì¹˜** ì´ìƒì´ë©´ ê¸ì •, ë¯¸ë§Œì´ë©´ ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜  
- ì¤‘ê°„ êµ¬ê°„(ì˜ˆ: `0.4 â‰¤ prob < 0.6`)ì„ **ì¤‘ë¦½**ìœ¼ë¡œ ì²˜ë¦¬í•´ ì• ë§¤í•œ ì‚¬ë¡€ë¥¼ ê±¸ëŸ¬ë‚¼ ìˆ˜ ìˆìŒ  

#### 2. ì†ì„±ë³„ ì„ê³„ì¹˜ í™œìš©
í™”ì¥í’ˆ ë¦¬ë·°ì²˜ëŸ¼ ì—¬ëŸ¬ ì†ì„±(ë¯¸ë°±, ë³´ìŠµ, íŠ¸ëŸ¬ë¸” ë“±)ì„ ë™ì‹œì— ë¶„ì„í•  ë•Œ,  
ê° ì†ì„±ë³„ë¡œ ë‹¤ë¥¸ ì„ê³„ì¹˜ë¥¼ ì„¤ì •í•˜ë©´ ë” ì„¸ë°€í•œ ë¼ë²¨ë§ì´ ê°€ëŠ¥

```python
# ì†ì„±ë³„ ì„ê³„ì¹˜ ì˜ˆì‹œ
thresholds = {
    'ë¯¸ë°±': {'pos': 0.6, 'neg': 0.5},
    'ë³´ìŠµ': {'pos': 0.5, 'neg': 0.5},
    'íŠ¸ëŸ¬ë¸”': {'pos': 0.4, 'neg': 0.5},
}

def label_aspect(aspect, prob_pos, prob_neg):
    thr = thresholds[aspect]
    if prob_pos >= thr['pos']:
        return f"{aspect} ê¸ì •"
    elif prob_neg >= thr['neg']:
        return f"{aspect} ë¶€ì •"
    else:
        return f"{aspect} ì¤‘ë¦½"
```

1. ì†ì„± ì–¸ê¸‰ ì‹œ ì£¼ë³€ì— ê¸ì • í‚¤ì›Œë“œâ†’ ë¼ë²¨ = `'ê¸ì •'`
2. ë¶€ì • í‚¤ì›Œë“œ ì£¼ë³€ì— ë¶€ì • í‚¤ì›Œë“œ â†’ ë¼ë²¨ = `'ë¶€ì •'`
3. ê¸°íƒ€ ì–¸ê¸‰ë§Œ ìˆì„ ê²½ìš°â†’ ë¼ë²¨ = `'ì¤‘ë¦½'`


# 4) ì‹¤ì œ ë³€í™˜í•´ì„œ ì›ë³¸ì— ë¶™ì´ê¸°(ë°±í„°í™”)
vector_df = fast_convert_label_to_vector(df_all['ë¼ë²¨'])
df_vectorized = pd.concat([df_all, vector_df], axis=1)
5ê°œ ì†ì„± Ã— 3ê·¹ì„± â†’ 15ì°¨ì› ì´ì§„ ë²¡í„°

```python
# 3) ë²¡í„° ë³€í™˜ í•¨ìˆ˜ ì •ì˜
def fast_convert_label_to_vector(label_series):
    result = []
    for label in label_series:
        # ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ì±„ì›Œì§„ ë”•ì…”ë„ˆë¦¬
        vector = {col: 0 for col in label_columns}
        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœ(label_review ë°˜í™˜ê°’)ë¼ë©´
        if isinstance(label, dict):
            for aspect, polarity in label.items():
                key = f"{aspect}_{polarity}"
                if key in vector:
                    vector[key] = 1
        result.append(vector)
    return pd.DataFrame(result)
```



# ëª¨ë¸ í•™ìŠµ
## ëª¨ë¸ ì•„í‚¤í…ì²˜

### 1) ê¸°ë³¸ LSTM ëª¨ë¸
#### ë‹¨ë°©í–¥ ë¹ ë¥¸ í•™ìŠµ
####  ë‹¨ë°©í–¥ RNN êµ¬ì¡°ë¡œ ì´ì „ ì‹œì  ì •ë³´ë§Œ í™œìš©. í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ ë¬¸ì¥ ë’·ë¶€ë¶„ ë§¥ë½ ë°˜ì˜ì— í•œê³„ê°€ ìˆìŒ.

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense

model = Sequential([
  Embedding(vocab_size, 128, input_length=max_len),
  LSTM(64),
  Dropout(0.5),
  Dense(64, activation='relu'),
  Dropout(0.5),
  Dense(15, activation='sigmoid')
])
model.compile(
  optimizer='adam',
  loss='binary_crossentropy',
  metrics=['accuracy']
)
```
###  2) Bi-LSTM+Attention
####  ì–‘ë°©í–¥ ë¬¸ë§¥ê³¼ í•µì‹¬ í† í° ê°•ì¡°
####  ìˆœë°©í–¥ê³¼ ì—­ë°©í–¥ LSTMì„ ê²°í•©í•´ ê³¼ê±°Â·ë¯¸ë˜ ì–‘ìª½ ë¬¸ë§¥ì„ ëª¨ë‘ í¬ì°©. íŠ¹íˆ ê¸´ ë¬¸ì¥ì—ì„œ ì•Â·ë’¤ ë§¥ë½ì„ ê· í˜• ìˆê²Œ í•™ìŠµ
#### í•µì‹¬ ê°ì„± í‘œí˜„(ì˜ˆ: "ì´‰ì´‰", "ìê·¹")ì— ì§‘ì¤‘ì‹œì¼œ ì„±ëŠ¥ì„ ë†’ì—¬ì¤Œ  



```python
from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Layer
from tensorflow.keras.models import Model

# ê°„ë‹¨í•œ Attention ë ˆì´ì–´ ì •ì˜
class Attention(Layer):
    def build(self, input_shape):
        self.W = self.add_weight(shape=(input_shape[-1], 1),
                                 initializer='glorot_uniform',
                                 trainable=True)
    def call(self, x):
        e = tf.matmul(x, self.W)           # (batch, seq_len, 1)
        a = tf.nn.softmax(e, axis=1)       # (batch, seq_len, 1)
        return tf.reduce_sum(x * a, axis=1)  # (batch, hidden_size)

inputs = Input(shape=(max_len,))
x = Embedding(vocab_size, 128)(inputs)
x = Bidirectional(LSTM(64, return_sequences=True))(x)
context = Attention()(x)
outputs = Dense(15, activation='sigmoid')(context)

model = Model(inputs, outputs)
model.compile(
  optimizer='adam',
  loss='binary_crossentropy',
  metrics=['accuracy']
)


```
![image](https://github.com/user-attachments/assets/4566d14e-895b-462f-b2a6-80b4edf5650b)
#### ì„±ëŠ¥ì´ 56%ì— ë¨¸ë¬´ë¥¸ë‹¤ëŠ” ê²ƒì€, ì´ì œ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë„£ê¸°ê¹Œì§€ì˜ ê³¼ì •, ì¦‰ 'ì „ì²˜ë¦¬(Preprocessing)'ë‚˜ í•™ìŠµ íŒŒë¼ë¯¸í„°ì— ë¬¸ì œ
#### ë¦¬ë·° í…ìŠ¤íŠ¸(ë¬¸ì¥)ë¥¼ ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ê³ , ëª¨ë“  ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ëŠ” ê³¼ì •
#### ê³µê°œëœ í•œêµ­ì–´ Word2Vec, FastText, ë˜ëŠ” KoBERT, KR-BERT ê°™ì€ ëª¨ë¸ì˜ ì„ë² ë”©ì„ ê°€ì ¸ì™€ì„œ, ëª¨ë¸ì˜ ì²« ë²ˆì§¸ Embedding ë ˆì´ì–´ì— ì ìš©ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ëŠë‚Œ

## ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ 
### ì¶”ì²œ ë¡œì§
![250624 ì‹œì—°](https://github.com/user-attachments/assets/02a85b57-83e3-4783-8937-b21649b68fd3)

1. **ë‹¤ì¤‘ í•„í„°**: ì¡°ê±´ ë§Œì¡± ì œí’ˆ ì„ ë³„ (í”¼ë¶€íƒ€ì…, ì¤‘ì ê¸°ëŠ¥(ë¯¸ë°±,ë³´ìŠµ,íŠ¸ëŸ¬ë¸”,ë³´í˜¸,ë…¸í™”ë°©ì§€))
2. **ê°œì¸í™” ì ìˆ˜**: Î£(ê¸ì •Ã—ê°€ì¤‘ì¹˜) âˆ’ Î£(ë¶€ì •Ã—ê°€ì¤‘ì¹˜)
   
![image](https://github.com/user-attachments/assets/0ca6b86f-b4cb-44fd-b855-c1917c5cdfca)

![image](https://github.com/user-attachments/assets/8a410e31-699b-47b2-802e-b1e6cd2893f7)
![image](https://github.com/user-attachments/assets/8d5bfe17-3ddb-492c-8725-50e6ed61a351)


![image](https://github.com/user-attachments/assets/bc57087e-e801-47ee-9f48-a6053d7288ca)

### íŒŒì¼ì„ ì—…ë¡œë“œë¥¼ í•˜ë©´ í”¼ë¶€íƒ€ì…(ê±´ì„±,ë¯¼ê°ì„±,ì§€ì„±,ì¤‘ì„±), ì¤‘ì ê¸°ëŠ¥(ë¯¸ë°±,ë³´ìŠµ,íŠ¸ëŸ¬ë¸”,ë³´í˜¸,ë…¸í™”ë°©ì§€)ì— 
### ë§ëŠ” ì œí’ˆì„ ì¶”ì²œí•´ì£¼ê³ , ìƒì„¸ ê¸ ë¶€ì • ë¹„ìœ¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ

### ì—…ë¡œë“œë¥¼ í•´ì„œ ë¶„ì„í•˜ëŠ”ê²ƒì´ ì•„ë‹Œ, ì‚¬ìš©ìê°€ í”¼ë¶€íƒ€ì…ê³¼ ê³ ë¯¼ì„ ì„ íƒí•˜ë©´ ì¶”ì²œ ì œí’ˆìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²ƒìœ¼ë¡œ ë³€ê²½ì´ í•„ìš”í•¨
