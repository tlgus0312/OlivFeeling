{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5787b7-75ac-4fa4-aad6-184326bebbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369f08aa-bc47-4416-9d6d-679bf5a60630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch ë²„ì „: 2.7.1+cu118\n",
      "CUDA ë¹Œë“œ ë²„ì „: 11.8\n",
      "\n",
      "-------------------------------------------\n",
      "      ğŸ‰ğŸ‰ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰ğŸ‰\n",
      "-------------------------------------------\n",
      "  í˜„ì¬ GPU ì¥ì¹˜: NVIDIA RTX A4000\n",
      "  GPU ì¥ì¹˜ ê°œìˆ˜: 1\n",
      "\n",
      "  GPUì—ì„œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "  ê²°ê³¼ í…ì„œì˜ ì¥ì¹˜: cuda:0\n",
      "  GPU ì—°ì‚° ì„±ê³µ!\n",
      "\n",
      "ëª¨ë¸ ë° ë°ì´í„°ì— ì‚¬ìš©í•  ìµœì¢… ì¥ì¹˜: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ë¹Œë“œ ë²„ì „: {torch.version.cuda}\") # PyTorchê°€ ë¹Œë“œëœ CUDA ë²„ì „\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(\"      ğŸ‰ğŸ‰ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰ğŸ‰\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"  í˜„ì¬ GPU ì¥ì¹˜: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU ì¥ì¹˜ ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    device = torch.device(\"cuda\") # GPU ì‚¬ìš©\n",
    "    \n",
    "    # ê°„ë‹¨í•œ GPU ì—°ì‚° í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\n  GPUì—ì„œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "    x = torch.rand(5, 5).to(device)\n",
    "    y = torch.rand(5, 5).to(device)\n",
    "    z = x + y\n",
    "    print(f\"  ê²°ê³¼ í…ì„œì˜ ì¥ì¹˜: {z.device}\")\n",
    "    print(f\"  GPU ì—°ì‚° ì„±ê³µ!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(\"      ğŸ˜­ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜­\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"  CUDA ë¹Œë“œ ë²„ì „ì´ Noneì´ê±°ë‚˜, torch.cuda.is_available()ì´ Falseì…ë‹ˆë‹¤.\")\n",
    "    print(\"  NVIDIA ë“œë¼ì´ë²„, CUDA Toolkit, cuDNN ì„¤ì¹˜ ìƒíƒœë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    device = torch.device(\"cpu\") # CPU ì‚¬ìš©\n",
    "\n",
    "print(f\"\\nëª¨ë¸ ë° ë°ì´í„°ì— ì‚¬ìš©í•  ìµœì¢… ì¥ì¹˜: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8bb5cc-50e4-4afa-be54-ba4645f7575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU device count: 1\n",
      "First GPU name: NVIDIA RTX A4000\n",
      "True 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# GPUê°€ ëª‡ ê°œë‚˜ ìˆëŠ”ì§€ë„ í™•ì¸\n",
    "print(\"GPU device count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"First GPU name:\", torch.cuda.get_device_name(0))\n",
    "    import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae9db6a-ee4e-4a6c-b756-41d94b9b0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda) # PyTorchê°€ ë¹Œë“œëœ CUDA ë²„ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1d28273-dcdd-4b1c-b9ae-b26af928717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… slow tokenizer ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# use_fast=False ë¡œ slow tokenizer ì‚¬ìš©\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"skt/kobert-base-v1\",\n",
    "    use_fast=False\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"skt/kobert-base-v1\",\n",
    "    num_labels=15\n",
    ")\n",
    "\n",
    "print(\"âœ… slow tokenizer ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18437bd-84c6-4f78-96cc-1008d4b54367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â‘  ë¶„ë¥˜ê¸° ë¡œë“œ\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "labels = [\n",
    "    'ë¯¸ë°±_ê¸ì •','ë¯¸ë°±_ì¤‘ë¦½','ë¯¸ë°±_ë¶€ì •',\n",
    "    'ë³´ìŠµ_ê¸ì •','ë³´ìŠµ_ì¤‘ë¦½','ë³´ìŠµ_ë¶€ì •',\n",
    "    'íŠ¸ëŸ¬ë¸”_ê¸ì •','íŠ¸ëŸ¬ë¸”_ì¤‘ë¦½','íŠ¸ëŸ¬ë¸”_ë¶€ì •',\n",
    "    'í”¼ë¶€_ê¸ì •','í”¼ë¶€_ì¤‘ë¦½','í”¼ë¶€_ë¶€ì •',\n",
    "    'ë…¸í™”_ê¸ì •','ë…¸í™”_ì¤‘ë¦½','ë…¸í™”_ë¶€ì •'\n",
    "]\n",
    "\n",
    "# â‘¡ ë¦¬ë·° CSV ë¡œë“œ (ì»¬ëŸ¼ëª…ì€ 'text' ì—¬ì•¼ í•©ë‹ˆë‹¤)\n",
    "df = pd.read_csv(\"raw_reviews.csv\")\n",
    "\n",
    "# â‘¢ ë¶„ë¥˜ í•¨ìˆ˜\n",
    "def zsl_label(text, threshold=0.5):\n",
    "    out = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    # score > threshold ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "    return { lab: int(score>threshold) \n",
    "             for lab, score in zip(out['labels'], out['scores']) }\n",
    "\n",
    "# â‘£ ëª¨ë“  ë¦¬ë·°ì— ì ìš©\n",
    "tqdm.pandas(desc=\"Zero-Shot ë¼ë²¨ë§\")\n",
    "labels_df = df['text'].progress_apply(zsl_label).apply(pd.Series)\n",
    "\n",
    "# â‘¤ ì›ë³¸ + ë¼ë²¨ í•©ì¹˜ê¸°\n",
    "df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "\n",
    "# â‘¥ ê²°ê³¼ ì €ì¥\n",
    "df_labeled.to_csv(\"raw_reviews_zero_shot_labeled.csv\", index=False)\n",
    "print(\"âœ… ì™„ë£Œ: raw_reviews_zero_shot_labeled.csv ìƒì„±ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863768e-9286-4765-a8ff-581be066718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (íŒŒì¼ì´ ìˆëŠ” í´ë”)\n",
    "os.chdir(r\"C:\\Users\\User\\Desktop\\skindata\")\n",
    "\n",
    "# 2) Zero-Shot ë¶„ë¥˜ê¸° ë¡œë“œ\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=0  # GPU ì‚¬ìš© ì‹œ 0ìœ¼ë¡œ ë³€ê²½\n",
    ")\n",
    "\n",
    "# 3) ë¼ë²¨ í›„ë³´ ëª©ë¡ (15ê°œ)\n",
    "candidate_labels = [\n",
    "    'ë¯¸ë°±_ê¸ì •','ë¯¸ë°±_ì¤‘ë¦½','ë¯¸ë°±_ë¶€ì •',\n",
    "    'ë³´ìŠµ_ê¸ì •','ë³´ìŠµ_ì¤‘ë¦½','ë³´ìŠµ_ë¶€ì •',\n",
    "    'íŠ¸ëŸ¬ë¸”_ê¸ì •','íŠ¸ëŸ¬ë¸”_ì¤‘ë¦½','íŠ¸ëŸ¬ë¸”_ë¶€ì •',\n",
    "    'í”¼ë¶€_ê¸ì •','í”¼ë¶€_ì¤‘ë¦½','í”¼ë¶€_ë¶€ì •',\n",
    "    'ë…¸í™”_ê¸ì •','ë…¸í™”_ì¤‘ë¦½','ë…¸í™”_ë¶€ì •'\n",
    "]\n",
    "\n",
    "# 4) ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜\n",
    "def zsl_label(ë¦¬ë·°, threshold=0.5):\n",
    "    out = classifier(ë¦¬ë·°, candidate_labels=candidate_labels, multi_label=True)\n",
    "    return {lab: int(score > threshold) for lab, score in zip(out['labels'], out['scores'])}\n",
    "\n",
    "# 5) í´ë” ë‚´ ëª¨ë“  *_reviews.csv íŒŒì¼ ì²˜ë¦¬\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot ë¼ë²¨ë§: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) ë¦¬ë·° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë¼ë²¨ë§ ìˆ˜í–‰\n",
    "    labels_df = df['ë¦¬ë·°ë‚´ìš©'].progress_apply(zsl_label).apply(pd.Series)\n",
    "    \n",
    "    # 7) ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ í•©ì¹˜ê¸°\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) ì €ì¥ (íŒŒì¼ëª…_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  íŒŒì¼ Zero-Shot ë¼ë²¨ë§ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84ef57a-f408-4ec7-8fe7-e5bb2d0c9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: ìŠ¤í‚¨_í† ë„ˆ_reviews.csv:   4%|â–ˆâ–                                | 1636/44144 [03:30<1:31:01,  7.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero-Shot ë¼ë²¨ë§: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 6) ë¦¬ë·° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë¼ë²¨ë§ ìˆ˜í–‰ (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m labels_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43më¦¬ë·°ë‚´ìš©\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzsl_label_single_sentiment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 7) ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ í•©ì¹˜ê¸°\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df_labeled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, labels_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4811\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m, in \u001b[0;36mzsl_label_single_sentiment\u001b[1;34m(ë¦¬ë·°, threshold)\u001b[0m\n\u001b[0;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr, labels \u001b[38;5;129;01min\u001b[39;00m attribute_labels\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# ê° ì†ì„±ë³„ (ì˜ˆ: ë¯¸ë°±) ê¸ì •/ì¤‘ë¦½/ë¶€ì • ë¼ë²¨ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43më¦¬ë·°\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <--- multi_label=False ì²˜ëŸ¼ ë™ì‘í•˜ë„ë¡\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ë¼ë²¨ì„ ì°¾ìŠµë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     best_label \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:204\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[1;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\base.py:1456\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:729\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 729\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\autograd\\profiler.py:771\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\_ops.py:1158\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5) í´ë” ë‚´ ëª¨ë“  *_reviews.csv íŒŒì¼ ì²˜ë¦¬\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot ë¼ë²¨ë§: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) ë¦¬ë·° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë¼ë²¨ë§ ìˆ˜í–‰ (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    labels_df = df['ë¦¬ë·°ë‚´ìš©'].progress_apply(zsl_label_single_sentiment).apply(pd.Series)\n",
    "    \n",
    "    # 7) ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ í•©ì¹˜ê¸°\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) ì €ì¥ (íŒŒì¼ëª…_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  íŒŒì¼ Zero-Shot ë¼ë²¨ë§ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88251f21-4fb9-4523-969d-cb099d79db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Device set to use cuda:0\n",
      "Zero-Shot ë¼ë²¨ë§: ìŠ¤í‚¨_í† ë„ˆ_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44144/44144 [1:28:05<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ìŠ¤í‚¨_í† ë„ˆ_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: ì•„ì´í¬ë¦¼_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32106/32106 [1:03:26<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ì•„ì´í¬ë¦¼_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: ì—ì„¼ìŠ¤_ì„¸ëŸ¼_ì•°í”Œ_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46326/46326 [1:32:54<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ì—ì„¼ìŠ¤_ì„¸ëŸ¼_ì•°í”Œ_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: ì˜¤ì¼_ë°¤_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43564/43564 [1:26:37<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ì˜¤ì¼_ë°¤_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: ì›Œí„°_ë°€í¬_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42102/42102 [1:24:48<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: ì›Œí„°_ë°€í¬_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: í¬ë¦¼_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42560/42560 [1:25:14<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: í¬ë¦¼_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot ë¼ë²¨ë§: í´ë Œì§•í¼_ì ¤_reviews.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46568/46568 [1:33:25<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: í´ë Œì§•í¼_ì ¤_zero_shot_labeled.csv\n",
      "ğŸ‰ ëª¨ë“  íŒŒì¼ Zero-Shot ë¼ë²¨ë§ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (íŒŒì¼ì´ ìˆëŠ” í´ë”)\n",
    "os.chdir(r\"C:\\Users\\User\\Desktop\\skindata\")\n",
    "\n",
    "# 2) Zero-Shot ë¶„ë¥˜ê¸° ë¡œë“œ\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=0  # GPU ì‚¬ìš© ì‹œ 0ìœ¼ë¡œ ë³€ê²½\n",
    ")\n",
    "\n",
    "# 3) ë¼ë²¨ í›„ë³´ ëª©ë¡ (15ê°œ)\n",
    "# ê° ì†ì„±ë³„ë¡œ ë¬¶ì–´ì„œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ í›„ì²˜ë¦¬ì— ìš©ì´í•©ë‹ˆë‹¤.\n",
    "attribute_labels = {\n",
    "    'ë¯¸ë°±': ['ë¯¸ë°±_ê¸ì •', 'ë¯¸ë°±_ì¤‘ë¦½', 'ë¯¸ë°±_ë¶€ì •'],\n",
    "    'ë³´ìŠµ': ['ë³´ìŠµ_ê¸ì •', 'ë³´ìŠµ_ì¤‘ë¦½', 'ë³´ìŠµ_ë¶€ì •'],\n",
    "    'íŠ¸ëŸ¬ë¸”': ['íŠ¸ëŸ¬ë¸”_ê¸ì •', 'íŠ¸ëŸ¬ë¸”_ì¤‘ë¦½', 'íŠ¸ëŸ¬ë¸”_ë¶€ì •'],\n",
    "    'í”¼ë¶€': ['í”¼ë¶€_ê¸ì •', 'í”¼ë¶€_ì¤‘ë¦½', 'í”¼ë¶€_ë¶€ì •'],\n",
    "    'ë…¸í™”': ['ë…¸í™”_ê¸ì •', 'ë…¸í™”_ì¤‘ë¦½', 'ë…¸í™”_ë¶€ì •']\n",
    "}\n",
    "\n",
    "# ëª¨ë“  í›„ë³´ ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "all_candidate_labels = sum(attribute_labels.values(), [])\n",
    "\n",
    "\n",
    "# 4) ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜ ìˆ˜ì •\n",
    "def zsl_label_single_sentiment(ë¦¬ë·°, threshold=0.5):\n",
    "    # ì´ ë¶€ë¶„ì€ ê° ì†ì„±(ë¯¸ë°±, ë³´ìŠµ ë“±)ë³„ë¡œ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    # multi_label=Falseë¡œ ì‘ë™í•˜ë„ë¡ í•˜ì—¬ ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ë¼ë²¨ë§Œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    results = {}\n",
    "    for attr, labels in attribute_labels.items():\n",
    "        # ê° ì†ì„±ë³„ (ì˜ˆ: ë¯¸ë°±) ê¸ì •/ì¤‘ë¦½/ë¶€ì • ë¼ë²¨ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜\n",
    "        out = classifier(ë¦¬ë·°, candidate_labels=labels, multi_label=False) # <--- multi_label=False ì²˜ëŸ¼ ë™ì‘í•˜ë„ë¡\n",
    "        \n",
    "        # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ë¼ë²¨ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "        best_label = out['labels'][0]\n",
    "        best_score = out['scores'][0]\n",
    "        \n",
    "        # ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ í•´ë‹¹ ë¼ë²¨ì—ë§Œ 1ì„ ë¶€ì—¬í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” 0\n",
    "        if best_score > threshold:\n",
    "            results[best_label] = 1\n",
    "            for lab in labels:\n",
    "                if lab != best_label:\n",
    "                    results[lab] = 0\n",
    "        else: # ì„ê³„ê°’ì„ ë„˜ì§€ ì•Šìœ¼ë©´ ëª¨ë‘ 0 (í•´ë‹¹ ì†ì„±ì— ëŒ€í•œ ëª…í™•í•œ ì–¸ê¸‰ ì—†ìŒ)\n",
    "            for lab in labels:\n",
    "                results[lab] = 0\n",
    "                \n",
    "    return results\n",
    "\n",
    "# 5) í´ë” ë‚´ ëª¨ë“  *_reviews.csv íŒŒì¼ ì²˜ë¦¬\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot ë¼ë²¨ë§: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) ë¦¬ë·° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë¼ë²¨ë§ ìˆ˜í–‰ (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    labels_df = df['ë¦¬ë·°ë‚´ìš©'].progress_apply(zsl_label_single_sentiment).apply(pd.Series)\n",
    "    \n",
    "    # 7) ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ í•©ì¹˜ê¸°\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) ì €ì¥ (íŒŒì¼ëª…_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  íŒŒì¼ Zero-Shot ë¼ë²¨ë§ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cb94032-95aa-48eb-bab0-e9095e4570d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading labeled files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 7ê°œ íŒŒì¼ í•©ì³ì„œ labeled.csv ì €ì¥ ì™„ë£Œ (ì´ 297370ê°œ í–‰)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1) í•©ì¹  íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "labeled_files = glob.glob(\"*_zero_shot_labeled.csv\")\n",
    "\n",
    "# 2) ê° íŒŒì¼ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°\n",
    "dfs = []\n",
    "for fp in tqdm(labeled_files, desc=\"Reading labeled files\"):\n",
    "    df = pd.read_csv(fp)\n",
    "    dfs.append(df)\n",
    "\n",
    "# 3) ì„¸ë¡œë¡œ í•©ì¹˜ê¸°\n",
    "combined = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# 4) ê²°ê³¼ ì €ì¥\n",
    "combined.to_csv(\"labeled.csv\", index=False)\n",
    "print(f\"âœ… {len(dfs)}ê°œ íŒŒì¼ í•©ì³ì„œ labeled.csv ì €ì¥ ì™„ë£Œ (ì´ {len(combined)}ê°œ í–‰)\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert",
   "language": "python",
   "name": "kobert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
