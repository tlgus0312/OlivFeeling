{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5787b7-75ac-4fa4-aad6-184326bebbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\kobert\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369f08aa-bc47-4416-9d6d-679bf5a60630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.7.1+cu118\n",
      "CUDA 빌드 버전: 11.8\n",
      "\n",
      "-------------------------------------------\n",
      "      🎉🎉 GPU를 사용할 수 있습니다! 🎉🎉\n",
      "-------------------------------------------\n",
      "  현재 GPU 장치: NVIDIA RTX A4000\n",
      "  GPU 장치 개수: 1\n",
      "\n",
      "  GPU에서 텐서 연산 테스트 중...\n",
      "  결과 텐서의 장치: cuda:0\n",
      "  GPU 연산 성공!\n",
      "\n",
      "모델 및 데이터에 사용할 최종 장치: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 빌드 버전: {torch.version.cuda}\") # PyTorch가 빌드된 CUDA 버전\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(\"      🎉🎉 GPU를 사용할 수 있습니다! 🎉🎉\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"  현재 GPU 장치: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU 장치 개수: {torch.cuda.device_count()}\")\n",
    "    device = torch.device(\"cuda\") # GPU 사용\n",
    "    \n",
    "    # 간단한 GPU 연산 테스트\n",
    "    print(\"\\n  GPU에서 텐서 연산 테스트 중...\")\n",
    "    x = torch.rand(5, 5).to(device)\n",
    "    y = torch.rand(5, 5).to(device)\n",
    "    z = x + y\n",
    "    print(f\"  결과 텐서의 장치: {z.device}\")\n",
    "    print(f\"  GPU 연산 성공!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(\"      😭 GPU를 사용할 수 없습니다. 😭\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"  CUDA 빌드 버전이 None이거나, torch.cuda.is_available()이 False입니다.\")\n",
    "    print(\"  NVIDIA 드라이버, CUDA Toolkit, cuDNN 설치 상태를 다시 확인해주세요.\")\n",
    "    device = torch.device(\"cpu\") # CPU 사용\n",
    "\n",
    "print(f\"\\n모델 및 데이터에 사용할 최종 장치: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8bb5cc-50e4-4afa-be54-ba4645f7575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU device count: 1\n",
      "First GPU name: NVIDIA RTX A4000\n",
      "True 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능하면 True, 아니면 False\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# GPU가 몇 개나 있는지도 확인\n",
    "print(\"GPU device count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"First GPU name:\", torch.cuda.get_device_name(0))\n",
    "    import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae9db6a-ee4e-4a6c-b756-41d94b9b0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda) # PyTorch가 빌드된 CUDA 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1d28273-dcdd-4b1c-b9ae-b26af928717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ slow tokenizer 로드 완료\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# use_fast=False 로 slow tokenizer 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"skt/kobert-base-v1\",\n",
    "    use_fast=False\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"skt/kobert-base-v1\",\n",
    "    num_labels=15\n",
    ")\n",
    "\n",
    "print(\"✅ slow tokenizer 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18437bd-84c6-4f78-96cc-1008d4b54367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ① 분류기 로드\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "labels = [\n",
    "    '미백_긍정','미백_중립','미백_부정',\n",
    "    '보습_긍정','보습_중립','보습_부정',\n",
    "    '트러블_긍정','트러블_중립','트러블_부정',\n",
    "    '피부_긍정','피부_중립','피부_부정',\n",
    "    '노화_긍정','노화_중립','노화_부정'\n",
    "]\n",
    "\n",
    "# ② 리뷰 CSV 로드 (컬럼명은 'text' 여야 합니다)\n",
    "df = pd.read_csv(\"raw_reviews.csv\")\n",
    "\n",
    "# ③ 분류 함수\n",
    "def zsl_label(text, threshold=0.5):\n",
    "    out = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    # score > threshold 면 1, 아니면 0\n",
    "    return { lab: int(score>threshold) \n",
    "             for lab, score in zip(out['labels'], out['scores']) }\n",
    "\n",
    "# ④ 모든 리뷰에 적용\n",
    "tqdm.pandas(desc=\"Zero-Shot 라벨링\")\n",
    "labels_df = df['text'].progress_apply(zsl_label).apply(pd.Series)\n",
    "\n",
    "# ⑤ 원본 + 라벨 합치기\n",
    "df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "\n",
    "# ⑥ 결과 저장\n",
    "df_labeled.to_csv(\"raw_reviews_zero_shot_labeled.csv\", index=False)\n",
    "print(\"✅ 완료: raw_reviews_zero_shot_labeled.csv 생성됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863768e-9286-4765-a8ff-581be066718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 작업 디렉토리로 이동 (파일이 있는 폴더)\n",
    "os.chdir(r\"C:\\Users\\User\\Desktop\\skindata\")\n",
    "\n",
    "# 2) Zero-Shot 분류기 로드\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=0  # GPU 사용 시 0으로 변경\n",
    ")\n",
    "\n",
    "# 3) 라벨 후보 목록 (15개)\n",
    "candidate_labels = [\n",
    "    '미백_긍정','미백_중립','미백_부정',\n",
    "    '보습_긍정','보습_중립','보습_부정',\n",
    "    '트러블_긍정','트러블_중립','트러블_부정',\n",
    "    '피부_긍정','피부_중립','피부_부정',\n",
    "    '노화_긍정','노화_중립','노화_부정'\n",
    "]\n",
    "\n",
    "# 4) 분류 함수 정의\n",
    "def zsl_label(리뷰, threshold=0.5):\n",
    "    out = classifier(리뷰, candidate_labels=candidate_labels, multi_label=True)\n",
    "    return {lab: int(score > threshold) for lab, score in zip(out['labels'], out['scores'])}\n",
    "\n",
    "# 5) 폴더 내 모든 *_reviews.csv 파일 처리\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot 라벨링: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) 리뷰 텍스트에 대해 라벨링 수행\n",
    "    labels_df = df['리뷰내용'].progress_apply(zsl_label).apply(pd.Series)\n",
    "    \n",
    "    # 7) 원본 데이터프레임과 합치기\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) 저장 (파일명_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"✅ 저장 완료: {output_file}\")\n",
    "\n",
    "print(\"🎉 모든 파일 Zero-Shot 라벨링 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d84ef57a-f408-4ec7-8fe7-e5bb2d0c9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 스킨_토너_reviews.csv:   4%|█▎                                | 1636/44144 [03:30<1:31:01,  7.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero-Shot 라벨링: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 6) 리뷰 텍스트에 대해 라벨링 수행 (수정된 함수 사용)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m labels_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m리뷰내용\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzsl_label_single_sentiment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 7) 원본 데이터프레임과 합치기\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df_labeled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, labels_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4811\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m, in \u001b[0;36mzsl_label_single_sentiment\u001b[1;34m(리뷰, threshold)\u001b[0m\n\u001b[0;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr, labels \u001b[38;5;129;01min\u001b[39;00m attribute_labels\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# 각 속성별 (예: 미백) 긍정/중립/부정 라벨만 사용하여 분류\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m리뷰\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <--- multi_label=False 처럼 동작하도록\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# 가장 높은 점수를 받은 라벨을 찾습니다.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     best_label \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:204\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[1;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\base.py:1456\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:729\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 729\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\autograd\\profiler.py:771\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kobert\\lib\\site-packages\\torch\\_ops.py:1158\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5) 폴더 내 모든 *_reviews.csv 파일 처리\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot 라벨링: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) 리뷰 텍스트에 대해 라벨링 수행 (수정된 함수 사용)\n",
    "    labels_df = df['리뷰내용'].progress_apply(zsl_label_single_sentiment).apply(pd.Series)\n",
    "    \n",
    "    # 7) 원본 데이터프레임과 합치기\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) 저장 (파일명_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"✅ 저장 완료: {output_file}\")\n",
    "\n",
    "print(\"🎉 모든 파일 Zero-Shot 라벨링 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88251f21-4fb9-4523-969d-cb099d79db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Device set to use cuda:0\n",
      "Zero-Shot 라벨링: 스킨_토너_reviews.csv: 100%|█████████████████████████████████| 44144/44144 [1:28:05<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 스킨_토너_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 아이크림_reviews.csv: 100%|██████████████████████████████████| 32106/32106 [1:03:26<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 아이크림_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 에센스_세럼_앰플_reviews.csv: 100%|██████████████████████████| 46326/46326 [1:32:54<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 에센스_세럼_앰플_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 오일_밤_reviews.csv: 100%|███████████████████████████████████| 43564/43564 [1:26:37<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 오일_밤_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 워터_밀크_reviews.csv: 100%|█████████████████████████████████| 42102/42102 [1:24:48<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 워터_밀크_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 크림_reviews.csv: 100%|██████████████████████████████████████| 42560/42560 [1:25:14<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 크림_zero_shot_labeled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot 라벨링: 클렌징폼_젤_reviews.csv: 100%|███████████████████████████████| 46568/46568 [1:33:25<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 클렌징폼_젤_zero_shot_labeled.csv\n",
      "🎉 모든 파일 Zero-Shot 라벨링 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 작업 디렉토리로 이동 (파일이 있는 폴더)\n",
    "os.chdir(r\"C:\\Users\\User\\Desktop\\skindata\")\n",
    "\n",
    "# 2) Zero-Shot 분류기 로드\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "    device=0  # GPU 사용 시 0으로 변경\n",
    ")\n",
    "\n",
    "# 3) 라벨 후보 목록 (15개)\n",
    "# 각 속성별로 묶어서 관리하는 것이 후처리에 용이합니다.\n",
    "attribute_labels = {\n",
    "    '미백': ['미백_긍정', '미백_중립', '미백_부정'],\n",
    "    '보습': ['보습_긍정', '보습_중립', '보습_부정'],\n",
    "    '트러블': ['트러블_긍정', '트러블_중립', '트러블_부정'],\n",
    "    '피부': ['피부_긍정', '피부_중립', '피부_부정'],\n",
    "    '노화': ['노화_긍정', '노화_중립', '노화_부정']\n",
    "}\n",
    "\n",
    "# 모든 후보 라벨을 리스트로 합칩니다.\n",
    "all_candidate_labels = sum(attribute_labels.values(), [])\n",
    "\n",
    "\n",
    "# 4) 분류 함수 정의 수정\n",
    "def zsl_label_single_sentiment(리뷰, threshold=0.5):\n",
    "    # 이 부분은 각 속성(미백, 보습 등)별로 분류를 수행합니다.\n",
    "    # multi_label=False로 작동하도록 하여 가장 점수가 높은 라벨만 선택합니다.\n",
    "    \n",
    "    results = {}\n",
    "    for attr, labels in attribute_labels.items():\n",
    "        # 각 속성별 (예: 미백) 긍정/중립/부정 라벨만 사용하여 분류\n",
    "        out = classifier(리뷰, candidate_labels=labels, multi_label=False) # <--- multi_label=False 처럼 동작하도록\n",
    "        \n",
    "        # 가장 높은 점수를 받은 라벨을 찾습니다.\n",
    "        best_label = out['labels'][0]\n",
    "        best_score = out['scores'][0]\n",
    "        \n",
    "        # 임계값을 넘으면 해당 라벨에만 1을 부여하고 나머지는 0\n",
    "        if best_score > threshold:\n",
    "            results[best_label] = 1\n",
    "            for lab in labels:\n",
    "                if lab != best_label:\n",
    "                    results[lab] = 0\n",
    "        else: # 임계값을 넘지 않으면 모두 0 (해당 속성에 대한 명확한 언급 없음)\n",
    "            for lab in labels:\n",
    "                results[lab] = 0\n",
    "                \n",
    "    return results\n",
    "\n",
    "# 5) 폴더 내 모든 *_reviews.csv 파일 처리\n",
    "csv_files = glob.glob(\"*_reviews.csv\")\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqdm.pandas(desc=f\"Zero-Shot 라벨링: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 6) 리뷰 텍스트에 대해 라벨링 수행 (수정된 함수 사용)\n",
    "    labels_df = df['리뷰내용'].progress_apply(zsl_label_single_sentiment).apply(pd.Series)\n",
    "    \n",
    "    # 7) 원본 데이터프레임과 합치기\n",
    "    df_labeled = pd.concat([df, labels_df], axis=1)\n",
    "    \n",
    "    # 8) 저장 (파일명_suffix)\n",
    "    output_file = file_path.replace(\"_reviews.csv\", \"_zero_shot_labeled.csv\")\n",
    "    df_labeled.to_csv(output_file, index=False)\n",
    "    print(f\"✅ 저장 완료: {output_file}\")\n",
    "\n",
    "print(\"🎉 모든 파일 Zero-Shot 라벨링 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cb94032-95aa-48eb-bab0-e9095e4570d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading labeled files: 100%|█████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 7개 파일 합쳐서 labeled.csv 저장 완료 (총 297370개 행)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1) 합칠 파일 목록 가져오기\n",
    "labeled_files = glob.glob(\"*_zero_shot_labeled.csv\")\n",
    "\n",
    "# 2) 각 파일을 읽어서 리스트에 담기\n",
    "dfs = []\n",
    "for fp in tqdm(labeled_files, desc=\"Reading labeled files\"):\n",
    "    df = pd.read_csv(fp)\n",
    "    dfs.append(df)\n",
    "\n",
    "# 3) 세로로 합치기\n",
    "combined = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# 4) 결과 저장\n",
    "combined.to_csv(\"labeled.csv\", index=False)\n",
    "print(f\"✅ {len(dfs)}개 파일 합쳐서 labeled.csv 저장 완료 (총 {len(combined)}개 행)\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert",
   "language": "python",
   "name": "kobert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
